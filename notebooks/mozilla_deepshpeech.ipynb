{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/pomoq-dev/video-clipping/blob/master/notebooks/mozilla_deepshpeech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "DIR_AUDIOS_VIDEOS = '/content/drive/MyDrive/INSTALL_VIDEOS'\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Git clone project and install requirements...')\n",
    "!git clone https://github.com/pomoq-dev/video-clipping.git &> /dev/null\n",
    "%cd video-clipping/\n",
    "\n",
    "!export PYTHONPATH=/content/video-clipping:$PYTHONPATH\n",
    "!wget https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp -O /usr/local/bin/yt-dlp\n",
    "!chmod a+rx /usr/local/bin/yt-dlp\n",
    "\n",
    "!pip install -r requirements.txt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install deepspeech\n",
    "!deepspeech --version"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO 0.9.3\n",
    "!mkdir deepspeech-0.8.2-models\n",
    "!wget https://github.com/mozilla/DeepSpeech/releases/download/v0.8.1/deepspeech-0.8.1-models.pbmm\n",
    "!wget https://github.com/mozilla/DeepSpeech/releases/download/v0.8.1/deepspeech-0.8.1-models.scorer\n",
    "!mv deepspeech-0.8.1-models.pbmm deepspeech-0.8.1-models.scorer deepspeech-0.8.2-models/\n",
    "!ls -l deepspeech-0.8.2-models/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import wave\n",
    "import deepspeech\n",
    "import numpy as np\n",
    "from vidlib import audio_tools\n",
    "\n",
    "model_file_path = 'deepspeech-0.8.2-models/deepspeech-0.8.1-models.pbmm'\n",
    "model = deepspeech.Model(model_file_path)\n",
    "scorer_file_path = 'deepspeech-0.8.2-models/deepspeech-0.8.1-models.scorer'\n",
    "model.enableExternalScorer(scorer_file_path)\n",
    "\n",
    "lm_alpha = 0.75\n",
    "lm_beta = 1.85\n",
    "model.setScorerAlphaBeta(lm_alpha, lm_beta)\n",
    "\n",
    "beam_width = 500\n",
    "model.setBeamWidth(beam_width)\n",
    "\n",
    "filename = 'input.wav'\n",
    "audio_tools.m4a2wav(os.path.join(DIR_AUDIOS_VIDEOS, 'audio0.m4a'), filename)\n",
    "w = wave.open(filename, 'r')\n",
    "rate = w.getframerate()\n",
    "frames = w.getnframes()\n",
    "buffer = w.readframes(frames)\n",
    "\n",
    "print(rate)\n",
    "print(model.sampleRate())\n",
    "print(str(type(buffer)))\n",
    "\n",
    "data16 = np.frombuffer(buffer, dtype=np.int16)\n",
    "print(str(type(data16)))\n",
    "\n",
    "text = model.stt(data16)\n",
    "print(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}